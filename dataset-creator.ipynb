{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Task:\n",
    "    - read the csv file \n",
    "    - download image separate them into training, test and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, urllib, csv,time\n",
    "\n",
    "class DataReader:\n",
    "    \n",
    "    def __init__(self,csvfile):\n",
    "        \n",
    "        self.csvfile = csvfile\n",
    "        self.regressionscore=[]\n",
    "        self.image_url=[]\n",
    "        self.downloadfolder='datasets'\n",
    "        self.labelstxt='labels.txt'\n",
    "\n",
    "        if not os.path.exists(os.path.join(os.getcwd(), self.downloadfolder)):\n",
    "            os.mkdir(os.path.join(os.getcwd(), self.downloadfolder))\n",
    "             \n",
    "    def csvReader(self):\n",
    "        with open(self.csvfile, 'rb') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=',')\n",
    "            for r in reader:\n",
    "                imageurl = r[0]\n",
    "                imagename = r[0].split('/')[-1]\n",
    "                score = r[1]\n",
    "                self.regressionscore.append(score)\n",
    "                self.labelsTxtCreator(imagename,score)\n",
    "                self.image_url.append(imageurl)\n",
    "                \n",
    "    def labelsTxtCreator(self,img_name,img_label):\n",
    "        f=open(self.labelstxt,'a')\n",
    "        txttowrite=img_name+','+img_label+'\\n'\n",
    "        f.write(txttowrite)\n",
    "        f.close()\n",
    "        \n",
    "    def imgDownloader(self):\n",
    "        img_count = len(self.image_url) \n",
    "        i=0\n",
    "        while i < img_count:\n",
    "            try:\n",
    "                img_name = self.image_url[i].split('/')[-1]\n",
    "                urllib.urlretrieve (self.image_url[i], os.path.join(os.getcwd(),self.downloadfolder,img_name))\n",
    "                print i,' th image downloaded'\n",
    "                i+=1\n",
    "            except IOError:\n",
    "                print 'error on' + i + 'th image'\n",
    "        \n",
    "    def calculateAverageScore(self):\n",
    "        np_array = np.array(self.regressionscore).astype('float')\n",
    "        return np.mean(np_array)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50294268497489492"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datareader = DataReader('dataset.csv')\n",
    "datareader.csvReader()\n",
    "datareader.imgDownloader()\n",
    "datareader.calculateAverageScore()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ratio of train, test and validator dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c', 'a', 'b']\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "a = list(['a','b','c'])\n",
    "b=['d','e']\n",
    "print a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "class trainTestandValidationDataCreator:\n",
    "    def __init__(self):\n",
    "        self.meanscore = 0.50294268497489492 # output from DataReader.calculateAverageScore()\n",
    "        self.per_train = .6\n",
    "        self.per_test = .2\n",
    "        self.per_validation = .2\n",
    "        self.img_names=[]\n",
    "        self.cls_labels=[]\n",
    "        self.labels_file = 'labels.txt'\n",
    "        \n",
    "    def createListOfImagesAndLabels(self):\n",
    "        '''\n",
    "        populates img_names=[] and scores=[]\n",
    "        score < mean == class 0\n",
    "        score > mean == class 1 \n",
    "        '''\n",
    "        f = open(self.labels_file,'r')\n",
    "        for line in f.readlines():\n",
    "            img_name,score = line.strip().split(',')\n",
    "            self.img_names.append(img_name)\n",
    "            cls_label = 0 if float(score) < self.meanscore else 1\n",
    "            self.cls_labels.append(cls_label)\n",
    "        f.close()\n",
    "\n",
    "    def createBalanceDataSet(self):\n",
    "        cls_one_imgs = [] # < mean\n",
    "        cls_two_imgs = [] # > means\n",
    "        \n",
    "        for img_name, score in zip(self.img_names,self.cls_labels):\n",
    "            if score == 0:\n",
    "                cls_one_img.append(img_name)\n",
    "            else:\n",
    "                cls_two_img.append(img_name)\n",
    "        \n",
    "        #shuffling the dataset\n",
    "        shuffle(cls_one_imgs)\n",
    "        shuffle(cls_two_imgs)\n",
    "        \n",
    "        #storage for training_datasets\n",
    "        training_datasets= []\n",
    "        training_labels= []\n",
    "        validation_datasets = []\n",
    "        validation_labels = []\n",
    "        test_datasets= []\n",
    "        test_labels =[]\n",
    "        \n",
    "        # creating dataset for class 0\n",
    "        total_class_one = len(cls_one_imgs)\n",
    "        num_training_img = int(total_class_one*self.per_train)\n",
    "        num_test_img = int(total_class_one*self.per_test)\n",
    "        num_val_img = total_class_one-num_training_img-num_test_img\n",
    "        \n",
    "        training_datasets +=cls_one_imgs[:num_training_img+1]\n",
    "        training_labels += [0]*num_training_img\n",
    "        \n",
    "        test_datasets+= cls_one_imgs[num_training_img+1:num_training_img+1+num_test_img]\n",
    "        test_labels+=[0]*num_test_img\n",
    "        \n",
    "        validation_datasets += cls_one_imgs[num_training_img+1+num_test_img:]\n",
    "        validation_labels += [0]*num_val_img\n",
    "        \n",
    "        # creating dataset for class 0\n",
    "        total_class_two = len(cls_two_imgs)\n",
    "        num_training_img = int(total_class_two*self.per_train)\n",
    "        num_test_img = int(total_class_two*self.per_test)\n",
    "        num_val_img = total_class_two-num_training_img-num_test_img\n",
    "        \n",
    "        training_datasets +=cls_two_imgs[:num_training_img+1]\n",
    "        training_labels += [1]*num_training_img\n",
    "        \n",
    "        test_datasets+= cls_two_imgs[num_training_img+1:num_training_img+1+num_test_img]\n",
    "        test_labels+=[1]*num_test_img\n",
    "        \n",
    "        validation_datasets += cls_two_imgs[num_training_img+1+num_test_img:]\n",
    "        validation_labels += [1]*num_val_img\n",
    "        \n",
    "        \n",
    "        \n",
    "        return cls_one_imgs, cls_two_imgs\n",
    "                \n",
    "        \n",
    "    def createDatasetForClassificationProblem(self):\n",
    "        '''\n",
    "        create balanece \n",
    "        '''\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
