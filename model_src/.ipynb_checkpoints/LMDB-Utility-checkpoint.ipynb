{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lmdb,os,sys,math\n",
    "caffe_root = '/gpu1/adnan/caffe/'  # this file is expected to be in {caffe_root}/examples\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.61936998]]]\n",
      "image index in LMDB 0000000000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import lmdb\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import caffe.proto.caffe_pb2\n",
    "from  caffe.io import datum_to_array\n",
    "\n",
    "LMDB_FILE_NAME = \"test_score_lmdb\"\n",
    "LMDB_PATH = os.path.join(os.getcwd(),'..','LMDB_612',LMDB_FILE_NAME)\n",
    "env = lmdb.open(LMDB_PATH, readonly=True, lock=False)\n",
    "\n",
    "visualize = False\n",
    "number_of_images = 1\n",
    "datum = caffe.proto.caffe_pb2.Datum() #datum_pb2.Datum()\n",
    "\n",
    "with env.begin() as txn:\n",
    "    cur = txn.cursor()\n",
    "    \n",
    "    for i in xrange(number_of_images):\n",
    "        \n",
    "        if not cur.next():\n",
    "            cur.first()\n",
    "        # Read the current cursor\n",
    "        key, value = cur.item()\n",
    "        \n",
    "        # convert to datum\n",
    "        datum.ParseFromString(value)\n",
    "        \n",
    "        # Read the datum.data\n",
    "        img_data = datum_to_array(datum)\n",
    "       \n",
    "        if visualize:\n",
    "            plt.imshow(img_data.transpose([1,2,0]))\n",
    "            plt.show()\n",
    "        else:\n",
    "            print img_data\n",
    "            #plt.imsave('sample.png',img_data.transpose([1,2,0]))\n",
    "\n",
    "        print 'image index in LMDB '+ str(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: python convert_protomean.py proto.mean out.npy\n"
     ]
    }
   ],
   "source": [
    "print \"Usage: python convert_protomean.py proto.mean out.npy\"\n",
    "\n",
    "blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "\n",
    "BINARY_PROTO_FILE_NAME  ='image_mean.binaryproto'\n",
    "BINARY_PROTO_FILE_PATH  = os.path.join(os.getcwd(),BINARY_PROTO_FILE_NAME)\n",
    "\n",
    "NPY_FILE_NAME  ='image_mean.npy'\n",
    "NPY_FILE_PATH  = os.path.join(os.getcwd(),NPY_FILE_NAME)\n",
    "\n",
    "data = open( BINARY_PROTO_FILE_PATH, 'rb' ).read()\n",
    "blob.ParseFromString(data)\n",
    "arr = np.array( caffe.io.blobproto_to_array(blob) )\n",
    "out = arr[0]\n",
    "np.save( NPY_FILE_PATH , out )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# The train/test net protocol buffer definition\r\n",
      "net: \"regression_train_test.prototxt\"\r\n",
      "\r\n",
      "\r\n",
      "# test_iter specifies how many forward passes the test should carry out.\r\n",
      "# In the case of MNIST, we have test batch size 100 and 100 test iterations,\r\n",
      "# covering the full 10,000 testing images.\r\n",
      "test_iter: 10\r\n",
      "\r\n",
      "# Carry out testing every 500 training iterations.\r\n",
      "test_interval: 50\r\n",
      "\r\n",
      "# The base learning rate, momentum and the weight decay of the network.\r\n",
      "base_lr: 0.01\r\n",
      "momentum: 0.9\r\n",
      "weight_decay: 0.0005\r\n",
      "\r\n",
      "\r\n",
      "# The learning rate policy\r\n",
      "lr_policy: \"inv\"\r\n",
      "gamma: 0.0001\r\n",
      "power: 0.75\r\n",
      "\r\n",
      "\r\n",
      "# Display every 100 iterations\r\n",
      "display: 1\r\n",
      "\r\n",
      "# The maximum number of iterations\r\n",
      "max_iter: 100\r\n",
      "\r\n",
      "# snapshot intermediate results\r\n",
      "snapshot: 50\r\n",
      "snapshot_prefix: \"lenet_test\"\r\n",
      "\r\n",
      "# solver mode: CPU or GPU\r\n",
      "solver_mode: GPU\r\n"
     ]
    }
   ],
   "source": [
    "!cat regression_solver.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
